{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset_Generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSyeQqy3PIz/Ect7WHa7ot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Filippo-Tombari/PdeGraph/blob/main/Dataset_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8bhsWQnnU-i",
        "outputId": "d44f97f2-ac3d-4bd2-9301-8acf3c7d6616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oixC9pauY-Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "import torch\n",
        "from torch._C import dtype\n",
        "import h5py\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7uDWV_w8Rsr"
      },
      "outputs": [],
      "source": [
        "def readh5(filename):\n",
        "  with h5py.File(filename, \"r\") as f:\n",
        "      # List all groups\n",
        "      print(\"Keys: %s\" % f.keys())\n",
        "      a_group_key = list(f.keys())[0]\n",
        "\n",
        "      # Get the data\n",
        "      data = list(f[a_group_key])\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_1NVDJMGr5Y"
      },
      "outputs": [],
      "source": [
        "#Reshape data to obtain the shape necessary for the network\n",
        "def reshape_data(data, mode = 'test'):\n",
        "  if(mode == 'train'):\n",
        "    old_len = np.shape(data)[0]\n",
        "    data = np.delete(data, range(old_len-8239,old_len))\n",
        "  \n",
        "  return np.reshape(data, (int(np.shape(data)[0]/2),2), order = 'F')\n",
        "#Convert data from P2 discretization to P1, keeping only the vertices of the mesh\n",
        "def P2toP1(data, mode = 'test'):\n",
        "  data = reshape_data(data, mode)\n",
        "  new_data = data[(nodes[None,:] == vertices[:,None]).all(-1).any(0)]\n",
        "  return torch.from_numpy(new_data) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training set\n"
      ],
      "metadata": {
        "id": "bWKMqrZYL3Rl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDXQqI-4vU8d",
        "outputId": "9ecb4ae4-fcc5-490a-ba41-c5e4b703d510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/tesi/obstacle/Archivio_test.zip\n",
            "  inflating: S_NS_test_21_end_hdf5.h5  \n",
            "  inflating: params_NS_test_21_end.mat  \n",
            "  inflating: params_NS_test_21_1.mat  \n",
            "  inflating: S_NS_test_21_1_hdf5.h5  \n",
            "  inflating: S_NS_test_21_15_hdf5.h5  \n",
            "  inflating: params_NS_test_21_15.mat  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/tesi/obstacle/Archivio_train.zip #complete training set archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjeQIfNu8ieJ"
      },
      "outputs": [],
      "source": [
        "#Write the training filename \n",
        "train_filename = \"/content/S_NS_train_21_full_hdf5.h5\" \n",
        "train_data = readh5(filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#choose a training rollout based on a value of the parameter\n",
        "train_set = train_data[400*10:400*11] # a rollout is composed of 400 time steps"
      ],
      "metadata": {
        "id": "psrqbZlRIjVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NjxECZUO3gb"
      },
      "outputs": [],
      "source": [
        "# create a save in a file the new training set\n",
        "os.chdir('/content/drive/MyDrive/tesi/obstacle') #change directory according to the one that you want to use for saving the dataset\n",
        "train_set_new = [P2toP1(data,'train') for data in train_set]\n",
        "with open(\"train_set.pkl\", \"wb\") as fp:   #Pickling\n",
        "  pickle.dump(train_set_new, fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test set"
      ],
      "metadata": {
        "id": "BnxyJL4pMWnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/tesi/obstacle/Archivio_test.zip #complete test set archive"
      ],
      "metadata": {
        "id": "ijN82SebMeBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write the training filename that you want to use\n",
        "test_filename = \"/content/S_NS_test_21_15_hdf5.h5\"\n",
        "test_data = readh5(filename)"
      ],
      "metadata": {
        "id": "pKx7QKJ_Mn87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a save in a file the new test set\n",
        "os.chdir('/content/drive/MyDrive/tesi/obstacle')#change directory according to the one that you want to use for saving the dataset\n",
        "test_set = [P2toP1(data) for data in test_data]\n",
        "with open(\"test_set.pkl\", \"wb\") as fp:   #Pickling\n",
        "  pickle.dump(test_set, fp)"
      ],
      "metadata": {
        "id": "ZLzqE3Y4M5pm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}