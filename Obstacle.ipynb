{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Obstacle_vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfGHk58rqrjqAME22sf00p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Filippo-Tombari/PdeGraph/blob/main/Obstacle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2kP35hoTIj4"
      },
      "source": [
        "# Import the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8bhsWQnnU-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27166fe-12b2-4d08-f0af-175b5851dc71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/tesi/obstacle\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import install\n",
        "install.pytorchgeo()"
      ],
      "metadata": {
        "id": "VgwkK7o_CXeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc231b08-6369-4fb4-8ecf-583278f7417a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch geometric installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.fenics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay14CdnJTvl2",
        "outputId": "21437508-ff1f-477c-ab85-d3be285a7543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEniCS installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oixC9pauY-Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import functional\n",
        "from functional import asfield, plot, L2, buildconnectivity\n",
        "import gnns\n",
        "import dolfin\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import NeighborSampler\n",
        "import torch.optim as optim\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/tesi/obstacle\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVcsp5wLMzgA"
      },
      "source": [
        "# Loading and preparation of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUCsaAFU_xZu"
      },
      "outputs": [],
      "source": [
        "mesh_train = dolfin.cpp.mesh.Mesh(\"files/obstacleDFG.xml\")\n",
        "edge_index_train = buildconnectivity(mesh_train)\n",
        "edge_index_train = torch.t(torch.from_numpy(edge_index_train.astype('int32')).long())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrsCXJS_k3pM"
      },
      "source": [
        "Training data parameter: 1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbsEEcdW6CAb"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "with open(\"files/train_set.pkl\", \"rb\") as fp:   #Pickling\n",
        "  train_set_new = pickle.load(fp)\n",
        "  train_set_new = [data.float() for data in train_set_new]\n",
        "train_loader = NeighborSampler(edge_index_train, node_idx=None,\n",
        "                               sizes=[7, 6, 5], batch_size=train_set_new[0].size()[0])\n",
        "valid_loader = NeighborSampler(edge_index_train, node_idx=None,\n",
        "                                sizes=[-1], batch_size=train_set_new[0].size()[0])\n",
        "for bs, id, a in train_loader:\n",
        "  batch_size_train = bs\n",
        "  n_id_train = id\n",
        "  adjs_train = a#`adjs` holds a list of `(edge_index, e_id, size)` tuples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC4JnDWUyyKq"
      },
      "outputs": [],
      "source": [
        "dt = 2e-2\n",
        "train_set = [torch.cat((train_set_new[i],torch.full((train_set_new[0].shape[0],1), dt*i)), dim = 1) for i in range(len(train_set_new))]\n",
        "#choose a specific time window for the training set in order to capture the phenomenon that we want to predict\n",
        "train_set = train_set[200:300] # we choose the window [4s,6s]\n",
        "train_set = torch.stack(train_set).to(device) #now the training set has size sample size x nodes x features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlSJOxaRd4yA"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ovadBANzKu"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l2   = L2(mesh_train).float() # L2 norm for scalar functions\n",
        "lv22 = lambda v: l2(v[:,:,0].to(device)).pow(2).float() + l2(v[:,:,1].to(device)).pow(2).float()\n",
        "lv2  = lambda v: lv22(v).sqrt().float() # L2 norm for vectorial functions\n",
        "def loss(output, target):\n",
        "  return (lv2(target - output) / lv2(target)).mean().float()"
      ],
      "metadata": {
        "id": "pQ4GsxCjvNkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn = gnns.SAGE(3,256,3).to(device)\n",
        "valid_size = 25\n",
        "train_size = train_set.shape[0] - valid_size\n",
        "train = train_set[:train_size,:,:].to(device)\n",
        "valid = train_set[train_size:].to(device)\n",
        "batch_size = 25\n",
        "learningrate = 1e-1\n",
        "optimizer = optim.Adam(gnn.parameters(), lr=learningrate)\n",
        "model_chk_path = 'checkpoints/obstacle_chk.pt'\n",
        "rollout_train_loss = []\n",
        "mse_min = 10000\n",
        "early_stopping = 0\n",
        "epochs = 100 \n",
        "t = 1 # current epoch\n",
        "done = False\n",
        "while not done:\n",
        "      rollout_train_loss.clear()\n",
        "      for i in range(0,train_size,batch_size):\n",
        "        train_loss = 0\n",
        "        # training\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass\n",
        "        integrating = torch.stack([gnn.forward(u, adjs_train) for u in train[i:i+batch_size]], axis = 0)\n",
        "        train_out = (train[[0]] + dt*integrating.cumsum(axis = 0)).to(device)\n",
        "        train_loss = loss(train_out[:-1],train[i+1:i+batch_size])\n",
        "        # backpropagation\n",
        "        #torch.autograd.set_detect_anomaly(True)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        rollout_train_loss.append(train_loss.item())\n",
        "      #validation\n",
        "      with torch.no_grad():\n",
        "        integrating_valid = torch.stack([gnn.inference(u, valid_loader) for u in valid[0:]], axis = 0)\n",
        "        valid_out = valid[[0]] + dt*integrating_valid.cumsum(axis = 0)\n",
        "        valid_loss = loss(valid_out[:-1],valid[1:])\n",
        "\n",
        "      mse_train = sum(rollout_train_loss)/len(rollout_train_loss)\n",
        "      mse_valid = valid_loss\n",
        "      # print rollout number and MSE for training and validation set at each epoch\n",
        "      print(f\"Rollout {t:1f}: MSE_train {mse_train :6.3f}, MSE_valid {mse_valid :6.3f}\" )\n",
        "      if mse_valid < mse_min:\n",
        "        mse_min = mse_valid\n",
        "        valid_out_best = valid_out\n",
        "        torch.save(gnn, model_chk_path)\n",
        "        early_stopping = 0\n",
        "        print('Saving model checkpoint')\n",
        "      else:\n",
        "        early_stopping += 1\n",
        "      #stop the training after reaching the number of epochs\n",
        "      t += 1\n",
        "      #import pdb; pdb.set_trace()\n",
        "      if (t > epochs ): #or early_stopping == 20\n",
        "        done = True"
      ],
      "metadata": {
        "id": "xKxcHp4TwR9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C047RQkOK5d0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for i in range(valid_size):\n",
        "  plt.figure(figsize = (12,4))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.title(\"prediction\")\n",
        "  plot(asfield(valid_out_best[i][:,0:2].detach().numpy()))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.title(f\"T = {250 + i}\")\n",
        "  plot(asfield(train_set[50 + i][:,0:2].detach().numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsUgV6wQ-dOA"
      },
      "outputs": [],
      "source": [
        "# Righe di codice per salvare l'animazione in formato .gif\n",
        "import imageio\n",
        "\n",
        "def savegif(drawframe, frames, name, transparency = False, remove = True):\n",
        "    filenames = []\n",
        "    for i in range(frames):\n",
        "        # plot frame\n",
        "        drawframe(i)\n",
        "\n",
        "        # create file name and append it to a list\n",
        "        filename = f'{i}.png'\n",
        "        filenames.append(filename)\n",
        "\n",
        "        # save frame\n",
        "        plt.savefig(filename, transparency = transparency)\n",
        "        plt.close()\n",
        "    # build gif\n",
        "    with imageio.get_writer(name + '.gif', mode='I') as writer:\n",
        "        for filename in filenames:\n",
        "            image = imageio.imread(filename)\n",
        "            writer.append_data(image)\n",
        "\n",
        "    # Remove files\n",
        "    if(remove):\n",
        "        for filename in set(filenames):\n",
        "            os.remove(filename)\n",
        "\n",
        "def trajectorytogif(traj, dt, name):\n",
        "    def drawframe(i):\n",
        "        colorbar = dolfin.common.plotting.plot(asfield(traj[i][:,0:2].numpy()))\n",
        "        plt.colorbar(colorbar, shrink = 0.75)\n",
        "        plt.title(\"T = %.2f\" % (dt*i))\n",
        "        plt.axis(\"off\")\n",
        "    savegif(drawframe, frames = len(traj), name = name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vSAfESJBKzs"
      },
      "outputs": [],
      "source": [
        "trajectorytogif(valid_out_best, 1, name = \"best_prediction\") # crea e salva la gif (la si trova nella cartella dei file generati, a sx del notebook)\n",
        "\n",
        "# Nota: su Colab non si può, ma su jupyter notebook è invece possibile visualizzare poi la gif direttamente\n",
        "# dentro il notebook, e.g.\n",
        "\n",
        "# from  IPython.display import Image as show\n",
        "# show(\"esempio.gif\")"
      ]
    }
  ]
}